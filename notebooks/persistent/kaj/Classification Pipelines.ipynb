{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from elasticsearch import Elasticsearch\n",
    "from collections import defaultdict\n",
    "from habanero import Crossref, counts, cn\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The DOIBoost pipeline (for the golden standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DOIBoostPipeline():\n",
    "    def __init__(self, dataset = 'doiboost2018'):\n",
    "        \n",
    "        # get the mongo client\n",
    "        client = MongoClient('mongo')\n",
    "\n",
    "        # get the database\n",
    "        metadatadb = client.get_database('narcis')\n",
    "\n",
    "        # get the metadata collection\n",
    "        self.metacollection = metadatadb[dataset]\n",
    "        \n",
    "        # get the elasticsearch connection\n",
    "        es_host = \"elasticsnarcis\"\n",
    "        es_local = Elasticsearch([es_host])\n",
    "        self.es = es_local\n",
    "        \n",
    "        # set the elasticsearch index and doctype\n",
    "        self.searchindex = 'grid'\n",
    "        self.doctype = 'metadata'\n",
    "    \n",
    "    \n",
    "    def metadata_retriever(self, DOI):\n",
    "        \"\"\"\n",
    "        Retrieves metadata when an DOI is provided.\n",
    "\n",
    "        @param  Collection   The metadata collection\n",
    "        @param  string       The DOI\n",
    "        @return dict         The corresponding metadata\n",
    "        \"\"\"\n",
    "    \n",
    "        # find the metadata with the DOI\n",
    "        subset = self.metacollection.find({'doi': DOI}).limit(1)\n",
    "\n",
    "        # return the first item\n",
    "        for item in subset:\n",
    "            return item\n",
    "\n",
    "        # there was no hit for the given DOI\n",
    "        return None\n",
    "    \n",
    "    def grid_ids_retriever(self, metadata):\n",
    "        \"\"\"\n",
    "        Uses metadata to retrieve the GRID ids\n",
    "\n",
    "        @param  dict    The metadata of a paper\n",
    "        @return array   The list of GRID ids    \n",
    "        \"\"\"\n",
    "\n",
    "        # initial list\n",
    "        gridIDs = []\n",
    "\n",
    "        # get the author information\n",
    "        authors = metadata['authors']\n",
    "\n",
    "        # loop over the authors in the list\n",
    "        for author in authors:\n",
    "\n",
    "            # get the affiliation(s) of the author\n",
    "            affiliations = author['affiliations']\n",
    "\n",
    "            # only continue if there is information about the affiliation\n",
    "            if affiliations:\n",
    "\n",
    "                # loop over the affiliation information\n",
    "                for affiliation in affiliations:\n",
    "\n",
    "                    # get the identifiers\n",
    "                    identifiers = affiliation['identifiers']\n",
    "\n",
    "                    # if one author doesn't have a GRID id, we can't be sure about the result\n",
    "                    if len(identifiers) < 2:\n",
    "                        return []\n",
    "\n",
    "                    # get the value of the second item, which is always the GRID id\n",
    "                    gridIDs.append(identifiers[1]['value'])\n",
    "\n",
    "        # return the list of affiliations\n",
    "        return gridIDs\n",
    "\n",
    "    def classify(self, gridIDs):\n",
    "        \"\"\"\n",
    "        Classify a research as Dutch/Non-Dutch based on the grid ids\n",
    "\n",
    "        @param  array    The grid IDs of the authors\n",
    "        @return boolean  True for Dutch, False for Non-Dutch\n",
    "        \"\"\"\n",
    "\n",
    "        # we can only classify with 100% True Positives and True Negatives\n",
    "        # if we have a complete list of GRID ids\n",
    "        if not gridIDs:\n",
    "            return None\n",
    "\n",
    "        # Get GRID data\n",
    "        for ID in gridIDs:\n",
    "            res = self.es.search(index=self.searchindex, doc_type=self.doctype, \n",
    "                                 body={\"query\": {\"match\": {'ID': \"%s\" % ID }}})\n",
    "            country = res['hits']['hits'][0]['_source']['Country']\n",
    "\n",
    "            # Verify Dutch affiliation\n",
    "            if country == 'Netherlands':\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "    \n",
    "    def pipeline(self, DOIs):\n",
    "        \"\"\"\n",
    "        The complete pipeline for identifying Dutch research using DOIBoost\n",
    "\n",
    "        @param  Collection    The DOIBoost collection in MongoDB\n",
    "        @param  array         The list of DOIs that need to be identified\n",
    "        @return dict          A dictionary with {DOI: classification} pairs\n",
    "        \"\"\"\n",
    "\n",
    "        # resulting dict\n",
    "        result = {}\n",
    "\n",
    "        # loop over the DOIs\n",
    "        for DOI in DOIs:\n",
    "\n",
    "            # retrieve the metadata\n",
    "            metadata = self.metadata_retriever(DOI)\n",
    "\n",
    "            # retrieve the GRID ids\n",
    "            gridIDs = self.grid_ids_retriever(metadata)\n",
    "\n",
    "            # skip if we don't have any GRID ids and can't be sure about the DOI identification\n",
    "            if gridIDs:\n",
    "\n",
    "                # classify the DOI based on the GRID ids\n",
    "                classification = self.classify(gridIDs)\n",
    "\n",
    "                # only add the classification if it's True or False\n",
    "                if classification is None:\n",
    "                    continue\n",
    "\n",
    "                # add the classification to the resulting dict\n",
    "                result[DOI] = classification\n",
    "\n",
    "        # return the result\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The CrossRef pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossRefPipeline():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # get the CrossRef API\n",
    "        self.cr = Crossref()\n",
    "        \n",
    "        # get the elasticsearch connection\n",
    "        es_host = \"elasticsnarcis\"\n",
    "        es_local = Elasticsearch([es_host])\n",
    "        self.es = es_local\n",
    "        \n",
    "        # set the elasticsearch index and doctype\n",
    "        self.searchindex = 'authors'\n",
    "        self.doctype = 'metadata'\n",
    "\n",
    "        \n",
    "    def metadata_retriever(self, DOI):\n",
    "        \"\"\"\n",
    "        Retrieves CrossRef metadata when an DOI is provided.\n",
    "\n",
    "        @param  string       The DOI\n",
    "        @return dict         The corresponding CrossRef metadata\n",
    "        \"\"\"\n",
    "\n",
    "        # find the metadata with the DOI\n",
    "        research = self.cr.works(ids = DOI)\n",
    "\n",
    "        # return the metadata\n",
    "        return research['message']\n",
    "    \n",
    "    def author_retriever(self, metadata):\n",
    "        \"\"\"\n",
    "        Retrieves the author names from the metadata and convert it to a string\n",
    "\n",
    "        @param  dict    The CrossRef metadata\n",
    "        @return array   The list of authors\n",
    "        \"\"\"\n",
    "\n",
    "        # get the authors\n",
    "        authors = metadata.get('author', None)\n",
    "\n",
    "        # stop if the metadata doesn't contain an author\n",
    "        if not authors:\n",
    "            return None\n",
    "\n",
    "        # the resulting list\n",
    "        result = []\n",
    "\n",
    "        # loop over the authors\n",
    "        for author in authors:\n",
    "\n",
    "            # retrieve the first name\n",
    "            name = author.get('given', None)\n",
    "\n",
    "            # retrieve the surname\n",
    "            surname = author.get('family', None)\n",
    "\n",
    "            # don't add the name if the surname is absent\n",
    "            if not surname:\n",
    "                continue\n",
    "\n",
    "            # add the first name before the surname if there is one\n",
    "            if name:\n",
    "                fullname = name + \" \" + surname\n",
    "            else:\n",
    "                fullname = surname\n",
    "\n",
    "            # add the name to the list\n",
    "            result.append(fullname)\n",
    "\n",
    "        # return the list of author names\n",
    "        return result\n",
    "    \n",
    "    def retrieve_countries(self, authors, metadata):\n",
    "        \"\"\"\n",
    "        Get the country of the authors\n",
    "\n",
    "        @param  array   A list of author names\n",
    "        @param  dict    The CrossRef metadata that contains the date of the research\n",
    "        @return array   The list of countries\n",
    "        \"\"\"\n",
    "\n",
    "        # resulting list\n",
    "        result = []\n",
    "\n",
    "        # loop over the authors\n",
    "        for author in authors:\n",
    "\n",
    "            # try to find the name in the author dataset\n",
    "            try:\n",
    "                res = es.search(index=self.searchindex, doc_type=self.doctype, \n",
    "                                body={\"query\": {\"match\": {'name': \"%s\" % author}}})\n",
    "                hits = res['hits']['hits']\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            # there are multiple hits\n",
    "            if len(hits) > 1:\n",
    "\n",
    "                # loop over the hits\n",
    "                for hit in hits:\n",
    "\n",
    "                    # add the first hit and move on to the next author\n",
    "                    result.append(hit['_source']['country'])\n",
    "                    break\n",
    "\n",
    "            # there is one hit, add it\n",
    "            else: \n",
    "                result.append(hits['_source']['country'])\n",
    "\n",
    "        # return the list of countries\n",
    "        return result\n",
    "    \n",
    "    def classify(self, countries):\n",
    "        \"\"\"\n",
    "        Classify the DOI as Dutch/Non Dutch\n",
    "\n",
    "        @param  array     The countries of the affiliations the authors work for\n",
    "        @return boolean   True for Dutch, False for Non Dutch\n",
    "        \"\"\"\n",
    "\n",
    "        # one of the countries has to be 'Netherlands' for the DOI to be classified as Dutch\n",
    "        if 'Netherlands' in countries:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def pipeline(self, DOIs):\n",
    "        \"\"\"\n",
    "        The complete pipeline for identifying Dutch research using DOIBoost\n",
    "\n",
    "        @param  Collection    The DOIBoost collection in MongoDB\n",
    "        @param  array         The list of DOIs that need to be identified\n",
    "        @return dict          A dictionary with {DOI: classification} pairs\n",
    "        \"\"\"\n",
    "\n",
    "        # resulting dict\n",
    "        result = {}\n",
    "\n",
    "        # loop over the DOIs\n",
    "        for DOI in DOIs:\n",
    "\n",
    "            # retrieve the metadata\n",
    "            metadata = self.metadata_retriever(DOI)\n",
    "            \n",
    "            # retrieve the authors from the metadata\n",
    "            authors = self.author_retriever(metadata)\n",
    "\n",
    "            # we need to have authors to continue\n",
    "            if authors:\n",
    "\n",
    "                # retrieve the countries of the authors\n",
    "                countries = self.retrieve_countries(authors, metadata)\n",
    "                \n",
    "                # classify the DOI based on the GRID ids\n",
    "                classification = self.classify(countries)\n",
    "\n",
    "                # add the classification to the resulting dict\n",
    "                result[DOI] = classification\n",
    "\n",
    "        # return the result\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(classifications, golden):\n",
    "    \"\"\"\n",
    "    Evaluate the classifier\n",
    "    \n",
    "    @param  dict   The labels from the classifier\n",
    "    @param  dict   The golden standard labels\n",
    "    @return dict   The True Positives, False Positives, True Negatives and False Negatives\n",
    "    \"\"\"\n",
    "    \n",
    "    # the resulting dict\n",
    "    result = defaultdict(int)\n",
    "    \n",
    "    # loop over the DOIs\n",
    "    for DOI in classifications:\n",
    "        \n",
    "        # get the label\n",
    "        classification = classifications[DOI]\n",
    "        \n",
    "        # get the golden label\n",
    "        gold = golden.get(DOI, None)\n",
    "        \n",
    "        # unknown if there is no golden label for the DOI\n",
    "        if (gold is None):\n",
    "            result['Unknown'] += 1\n",
    "        \n",
    "        # the label should be Positive\n",
    "        elif gold == True:\n",
    "            \n",
    "            # True Positive\n",
    "            if classification == True:\n",
    "                result['TP'] += 1\n",
    "            \n",
    "            # False Negative\n",
    "            else: \n",
    "                result['FN'] += 1\n",
    "        \n",
    "        # the label should be Negative\n",
    "        else:\n",
    "            \n",
    "            # True Negative\n",
    "            if classification == False:\n",
    "                result['TN'] += 1\n",
    "            \n",
    "            # False Positive\n",
    "            else: \n",
    "                result['FP'] += 1\n",
    "       \n",
    "    # return the result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets see the model in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOIs = ['10.1007/s00422-017-0730-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = DOIBoostPipeline('doiboost2017')\n",
    "doiboost_labels = D.pipeline(DOIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = CrossRefPipeline()\n",
    "crossref_labels = C.pipeline(DOIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'TN': 1})\n"
     ]
    }
   ],
   "source": [
    "evalutation_results = evaluation(crossref_labels, doiboost_labels)\n",
    "print(evalutation_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
